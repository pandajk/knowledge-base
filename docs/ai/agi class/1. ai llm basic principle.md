# 1. AI LLM Basic Principle

# AI大模型基本原理

#AGIClass AI大模型基本原理

##**1.什么是AI？**

ai的发展：

1. 计算智能
- 1946 第一台通用计算机诞生
- 1997 IBM深蓝战胜国际象棋世界冠军
- 2016 AlphaGO战胜围棋世界冠军
2. 感知智能
- 2010s 语音识别、图像识别
3. 通用智能
- 2022.11 GPT3.5爆发

基于机器学习、神经网络的是 AI，基于规则、搜索的不是 AI。

##**2.AI 大模型能做什么**

区分对话产品和大模型。

能力：

- 按格式输出
- 文本信息提取，按需求格式化输出
- 分类
- 文本内容分类
- 聚类
- 文本信息聚合
- 持续互动
-
- 技术相关问题、AGI 通用人工智能可能可以解决一切问题。

用【用人思维】使用 AI：

- 机器思维：研发了什么功能，就有什么功能
- 用人思维：给 ta 一个任务，总会有些反馈，或好或坏，惊喜或惊吓
1. 大模型就是一个函数，给输入，**生成**输出
- 大模型是真实世界的一个函数求解，输入参数，获得函数结果
- 目前通过海量参数模拟真实世界的规律
2. 任何可以用语言描述的问题，都可以输入文本给大模型，就能生成问题的结果文本
3. 进而，任意数据，都可以输入给大模型，生成任意数据
- 多模态支持
- 万物皆向量， 大模型GPT时代：一切皆为向量

##**3.大模型现阶段落地情况综述**

目前还没有“killer app”，目前 ai 主要应用在：

- AI 原生应用，产品核心功能是 AI
- 助手类，ChatGPT, Kimi Chat, ...
- 搜索类，Perplexity, 秘塔 AI，Devv
- 社交情感陪伴，Character.AI, 星野，Replika
- 定制 Agent，ChatGPT GPTs，扣子，dify
- AI 编程，Cursor，Windsurf，InsCode，marscode
- 在场景中，AI 辅助应用
- 拍照答题
- 英语学习
- 图像处理
- 办公
- 编程
- 全家桶
- 内部提效
- 营销
- AI 营销创意，人再加工
- AI 批量生产营销素材
- 多语言翻译
- 客服/销售
- 全 AI，适合本来没人做，AI 来补位
- 半 AI，适合本来有人做，AI 来提效
- 办公
- 公文撰写/总结/翻译
- 知识库
- 内部客服
- 辅助决策
- 情报分析
- BI
- 产品研发
- 创意、头脑风暴
- IT 研发提效

##**4. 怎样寻找大企业中大模型落地场景**

1. 业务流程解构
- 明确目标：明确解构目标，提升效率、降低成本、增强产品或服务质量
- 分析现有流程：通过沟通，了解当前的业务流程（工具：流程图、价值流图）
- 收集数据：收集与流程相关的数据，包括时间、资源、瓶颈，识别出目前流程中的问题和改进点
- 识别关键环节：确定每个环节对业务结果的影响，哪些是最能推动价值产生的，哪些是浪费或低效的
2. 绘制企业价值流图
- 识别关键流程
- 标记价值增值活动
- 流程中的浪费
- 时间与资源
- 改进方案
3. 识别大模型应用场景
- 数据驱动的决策
- 需要分析大量数据的场景，提供更精确的决策支持
- 分析客户数据，优化市场营销策略
- 自动化与智能化
- 应用于自动化任务
- 智能客服、语音识别、图像识别
- 减少人工成本，并提升效率
- 个性化服务
- 个性化推荐系统
- 基于用户历史行为、偏好，推荐个性化产品或服务，提高客户满意度和转化率
- 预测与优化
- 对历史数据分析，预测未来趋势
- 优化生产计划、库存管理
- 业务流程改进
- 利用大模型分析当前业务流程中的瓶颈和效率低下的环节，提供改进措施，优化资源配置

成功落地五要素：

1. 业务人员的积极
2. 对 AI 能力的认知
3. 业务团队自带编程能力
4. 从小处着手
5. 老板的耐心

如何找到落地的场景：

1. 从最熟悉的领域入手
2. 尽量找能用语音描述的任务
3. 别求大而全。将任务拆解，先解决小任务、小场景
4. 让 AI 学最厉害员工的能力，再让 ta 辅助其他员工，实现降本增效

##**5.大模型的通俗原理**

**通俗原理**：它是根据上下文猜下一个词的概率。。。。

**略深一点的通俗原理**：训练和推理是大模型工作的两个核心过程。训练是学，推理是用。学以致用，如是也。

训练：

1. 大模型阅读了人类说过的所有的话。这是「机器学习」
2. 训练过程会把不同 token 同时出现的概率存入「神经网络」文件。保存的数据就是「参数」，也叫「权重」

推理：

1. 我们给推理程序若干的 token，程序会加载大模型的权重，算出概率最高的下一个 token 是什么
2. 用生成的 token，再加上上文，就能继续生成下一个 token。以此类推，生成更多文字

more：大模型的随机性就是在推理的时候，下一个 token 概率排序中如何选择的策略。

**再深一点点：**

- 这套生成机制的内核加「Transformer 架构」
- Transformer 是目前人工智能领域最广泛流行的架构，被用在各个领域

**机器学习 ≈ 机器自动找一个函数**

- 函数：y = a*x + b
- 现实世界的客观规律很复杂，函数组合更复杂
- 已知：x = 1时，y=7；x=2时，y=5；求解 a，b
- 可以看做时训练 AI 的数据，用数据找到客观规律
- 现实世界数据会很多，计算量也会很大
- 用各种已知数据训练 AI
- 解：带入x，y；可得：a=2，b=5
- 现实世界很复杂，a、b 可能不是唯一解

大模型有海量参数，deepseek-r1:671b，参数量是 6710 亿个参数。

**标量、向量、矩阵、张量**

[点、线、面、体]

**Embedding是什么？**

1. 将文本、图像、音频等高维数据映射到低维空间，转化成向量数据
2. 不仅将数据转换成向量，还通过学习语义和上下文信息，使得向量能够更好地表现数据的内部特征（强调语义和上下文信息的捕捉）。

**Transformer核心：注意力机制 Attention Mechanism**

是一种基于 self-attention mechanism的深度学习架构，在 NLP 和 CV 领域取得巨大成功。

在传统 神经网络中（如循环神经网络RNN），模型需要按顺序处理序列数据，每个时间步的状态依赖与前一个时间步的输出，这会存在计算效率低、长距离依赖问题。注意力机制允许模型在处理每个时间步时，动态地关注整个序列中与当前任务最相关的信息，而不是固定地按顺序处理。

自注意力机制是一种特殊的注意力机制，用处理序列内部的关系。核心思想是：对于序列中的每个元素，计算它与其他所有元素的相关性或权重，并根据这些权重对整个序列进行加权求和。

#TODO 自注意力机制可用于带权重的线路规划吗？？

#TODO 深入了解自注意力机制

**注意力机制中的 Q、K、V**

**用好AI 的核心心法**

- 把 AI 当人看
- 数字神经网络和人脑的生物神经网络，在数学原理上是一样的
- 学习时当老师
- 工作时当助手
- 休闲时当朋友
- **使用大模型的好习惯**
- 不同的话题要开启新的会话
- 明确指令和问题，避免歧义的表达，多重含义或复杂结构
- 分步进行，如果问题复杂，将问题拆解成几个小问题，逐步处理，提供准确度，提高处理效率，避免大模型处理过于庞大的信息
- 上下文保留，在对个会话中，如果需要参考之前的对话，可以适当提及或复述关键点
- 分配优先级，针对多个任务或问题，可以为每个话题分配优先级，先处理最重要或最紧急的内容（大模型平台的策略）
- 适应模型的限制，了解模型的处理能力和上下文长度限制，避免输入过长文本
- 反馈循环，在模型回答不完全或不符合预期是，及时提供反馈和补充说明，让模型逐步优化回答
- 使用特定的格式或模板，在处理特定类型的任务或问题（代码、数学问题、写作任务等），可以输入提供特定的格式或模板，以帮助模型更准确地理解任务需求

##**6.大模型技术的短板**

- 对时效性内容的处理
- 大模型本身不能处理最新的事件和信息，通常只能处理到训练数据节点的信息
- 目前是通过联网查询解决这个问题
- 幻觉、不准确性和滥用风险
- 幻觉，是提供错误但看似合理的文本
- 这可能导致错误信息传播，甚至被用于非法或不道德的目的
- 泛化能力的局限性
- 是指在处理新的、未见过的数据时，虽然在别的任务上表现出色，但处理特定、罕见或新颖的情况时可能表现不佳
- 难以解释和透明性差
- 大模型通常是“黑箱“，即使是模型开发者也无法完全理解模型是如何配置自身以产生文本。且随着模型规模的增大，日益复杂

##**7.大模型应用架构**

**大模型应用产品架构**

- AI Embedded 模式
- 在某项任务中嵌入 ai
- AI Copilot 模式
- ai 辅助
- 目前主流架构是多 Agent 工作流
- 将业务拆成工作流（workflow, SOP, pipeline）
- 每个 Agent 负责一个工作流节点
- AI Agent 模式
- 目前还太超前

**大模型应用技术架构**

门槛低、天花板高

- 纯 prompt
- Agent + Function Calling
- RAG, Retrieval-Augmented Generation
- Fine-tuning
- 值得尝试的情况
- 提高模型输出的稳定性
- 用户量大，降低推理成本
- 提高大模型生成速度
- 需要私有部署

没有最好的大模型，只有最适合的大模型。

- 基础模型选择，合规、安全是首要考量因素
- 然后用测试数据，在备选模型中，测试找出最合适的
- 不要 依赖榜单
- 榜单可能被应试教育污染， [https://lmarena.ai/?leaderboard
]
- 榜单是整体能力，在具体事情上结果不一定最好
- 榜单没有体现成本

##**8.Deepseek 本地部署和应用**

ollama run deepseek-r1:8b

docker

本地部署可用于学习，实际使用在普通设备上效果不好，在不关心隐私的情况下优先使用 API 的方式。

课堂作业：

- 发掘身边大模型落地的场景
- 撰写自己的大模型应用构想，要求给出需求说明和期望的效果

